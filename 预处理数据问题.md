**预处理阶段的数据一致性问题**：你保存出来的 `X_train_<modality>.npy` 和 `y_train_*.npy` **不是同一批样本、同一套索引、同一套过滤/增强策略**生成的，所以长度对不上。你现在这个错（624 vs 1248）就是典型症状。

下面我按“为什么会发生 → 预处理阶段怎么避免（工程做法）→ 你项目里落地的最小规范”讲清楚。

------

## 1) 为什么会发生这种不一致（最常见 5 类原因）

### A. 各模态过滤规则不一致

比如 `filtered/powerspec` 某些 sample 可读，但 `att` 缺文件、或特征提取失败，你在构建 `X_att` 时跳过了样本；但 y 是按另一套模态生成的（没跳过/跳过的不同），就会不一致。

### B. 对某些模态做了增强/复制，但 y 用了另一套

你现在 y=1248 很像是 **数据增强后翻倍** 或 **拼接了更多样本**；但 `X_train_att` 还停留在增强前的 624。

### C. train/test 划分在不同阶段做了两次

比如一次先 split 再提特征；另一次先全量提特征再 split；或者不同随机种子，导致 X 和 y 不同版本。

### D. y 的保存方式不是“每样本一标签”

你以前有 one-hot encoder，某些保存可能把 `(N, C)` 展平、或保存成重复结构，导致你看到长度成倍变化。

### E. 样本顺序不一致（最危险、最隐蔽）

就算长度一致，如果 `os.listdir()` 在不同地方排序不同、或者某处 shuffle 了但没保存索引，也会导致 X 和 y “错位但不报错”，训练会变得很怪（这个比直接报错更糟）。

------

## 2) 预处理阶段如何**彻底避免**这类问题（工程级做法）

核心原则就一句话：

> **先建立“样本主索引（manifest）”，所有模态的 X 和 y 都必须按 manifest 的同一顺序生成和保存。**
> 宁可丢样本，也绝不能让模态之间的样本集合不一致。

### ✅ 做法 1：生成 `manifest.csv`（强烈推荐）

预处理时第一步就扫描数据目录，生成一个 manifest（样本清单），每行一条样本：

| sample_id | emotion | path | has_att | has_med | has_filtered | has_powerspec | valid |
| --------- | ------- | ---- | ------- | ------- | ------------ | ------------- | ----- |
|           |         |      |         |         |              |               |       |

然后你定义统一规则：

- `valid = has_att & has_med & has_filtered & has_powerspec`（所有模态齐全才保留）
- `sample_id` 必须稳定（例如 `happy/sample013`）
- 后续提取任何模态，都只遍历 `manifest[valid==True]`，并严格按 manifest 的顺序 append

这样你永远不会出现某个模态少一截的情况。

### ✅ 做法 2：任何“丢样本/过滤”的地方必须回写到 manifest

比如读 CSV 失败、产生 NaN、长度不足、窗口化失败，都必须标记这条 sample 为 invalid 并记录 reason，而不是“静默 continue”。

### ✅ 做法 3：train/test split 只做一次，并保存索引文件

split 完保存：

- `train_ids.txt`
- `test_ids.txt`
  或 `split.json`（保存随机种子、比例、每个集合的 sample_id 列表）

以后不允许再 split 第二次。

### ✅ 做法 4：增强必须只在训练集，并且“X 和 y 同步写入”

增强一条 X，就必须同时追加一条 y，并且最好在 `manifest_aug.csv` 里记录：

- `origin_sample_id`
- `aug_type`
- `new_sample_id`

避免出现“X 增强了，y 还是原来的长度”。

### ✅ 做法 5：保存时写入“形状与校验信息”

每次导出 `features/`，同时保存一个 `meta.json`：

```json
{
  "n_train": 624,
  "n_test": 156,
  "modalities": {
    "att": [624, 10, 4],
    "filtered": [624, 10, 4]
  },
  "y_train_shape": [624],
  "class_names": ["happy","sad","normal"],
  "split_seed": 42
}
```

下次训练前先读 meta.json 检查，不一致直接拒绝训练（你现在这个 ValueError 就是正确方向）。

------

## 3) 你应该如何在你当前项目里落地（最小改动方案）

你现在已经有一个 `features/` 导出目录了，我建议你把预处理导出变成固定产物集合：

### 必须产物（以后训练脚本只认它们）

- `manifest.csv`（或 `manifest.parquet`）
- `split.json`（train/test sample_id 列表）
- `X_train_<mod>.npy`, `X_test_<mod>.npy`
- `y_train.npy`, `y_test.npy`（只保留一份统一标签，不要按模态多份）
- `label_encoder.joblib`
- `meta.json`

然后强制约束：

- **不允许出现 `y_train_filtered.npy / y_train_att.npy` 这种多套 y 并存**
  它们是“漂移版本”的温床。

------

## 4) 你这次 624 vs 1248，最可能的具体原因

大概率是：

- `y_train_filtered.npy` 来自“增强后/拼接后”的标签版本（1248）
- 但 `X_train_att.npy` 来自“未增强”的版本（624）

这种问题就是因为：**增强发生在某个导出步骤里，但没有统一管理 manifest/split/meta**。

------

## 5) 你接下来怎么做（不绕弯）

1. **短期修复训练**：用与 X 同长度的 y（你已经有 `y_train_att.npy`）先跑通
2. **中期修复预处理**：重做一次导出，按上面规范生成 `manifest + split + meta`，并统一只输出 `y_train.npy/y_test.npy`

如果你愿意，我可以直接给你一个“预处理导出脚本”的模块化版本（`scripts/build_features_multimodal.py`），它会：

- 扫描 raw data
- 生成 manifest
- 一次性导出四模态 X + 统一 y
- 自动写 meta.json
- 保证以后永远不会再出现长度不一致

你不用再手动拼凑 `features/`。